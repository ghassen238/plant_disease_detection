# -*- coding: utf-8 -*-
"""plant_disease_detection.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EX4DCt0UoWvwjtdJQdsuEvs9Z_34rMO1
"""

import tensorflow as tf
from zipfile import ZipFile
import os,glob
import cv2
from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import MaxPooling2D
from keras.layers import Flatten

!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d vipoooool/new-plant-diseases-dataset

!unzip new-plant-diseases-dataset.zip -d data1/

from keras_preprocessing.image import ImageDataGenerator,load_img,img_to_array
from keras.applications.vgg19 import VGG19,preprocess_input,decode_predictions

train_data = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True, preprocessing_function=preprocess_input)
validation_data=ImageDataGenerator(preprocessing_function=preprocess_input)

train=train_data.flow_from_directory(directory='/content/data1/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train',
target_size=(256,256),
batch_size=32)

val=train=validation_data.flow_from_directory(directory='/content/data1/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid',
target_size =(256,256),
batch_size =32)

t_img,label=train.next()

t_img.shape

import matplotlib.pyplot as plt

def plotimage(img_arr , label):
  for im , l in zip(img_arr, label):
    plt.figure(figsize=(5,5))
    plt.imshow(im)
    plt.show()

plotimage(t_img[:3], label[:3])

base_model=VGG19(input_shape=(256,256,3), include_top=False)

for layer in base_model.layers:
  layer.trainable=False

X=Flatten()(base_model.output)

X=Dense(units=38, activation='softmax')(X)

from keras.models import Model

model=Model(base_model.input, X)

import keras

model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

from keras.callbacks import ModelCheckpoint, EarlyStopping

es=EarlyStopping(monitor='val_accuracy',
                 min_delta=0.01,
                 patience=3,
                 verbose=1)

mc=ModelCheckpoint(filepath='plantdiseasedetection.h5',
                   monitor='val_acccuracy',
                   min_delta=0.01,
                   patience=3 , 
                   verbose=1, 
                   save_best_only=True)

cb=[es,mc]

hist=model.fit(train,steps_per_epoch=16,
                         epochs=50,
                         verbose=1,
                         callbacks=cb,
                         validation_data=val,
                         validation_steps=16)

model.save('plantdiseasedetection.h5')

h=hist.history
h.keys()

plt.plot(h['accuracy'])
plt.plot(h['val_accuracy'], c ="red")
plt.title('acc vs val_acc')
plt.show()

plt.plot(h['loss'])
plt.plot(h['val_loss'], c ="black")
plt.title('loss vs val_loss')
plt.show()

ref=dict (zip(list(train.class_indices.values()) , list(train.class_indices.keys())))

def predict(path):
  img=load_img(path, target_size=(256,256))
  i=img_to_array(img)
  im=preprocess_input(i)
  img=np.expand_dims(im, axis=0)
  pred=np.argmax(model.predict(img))
  plt.imshow(i)
  plt.show()
  print(f'the image is {ref[pred]}')

path='/content/data1/test/test/PotatoEarlyBlight2.JPG'

predict('/content/data1/test/test/PotatoEarlyBlight2.JPG')

import pickle
pickle.dump(model,open('base_model.pkl', 'wb'))











